version: '3.8'

services:
  # Docker-in-Docker for AI tools
  dind:
    image: docker:24-dind
    container_name: ai-dind
    restart: unless-stopped
    privileged: true
    environment:
      - DOCKER_TLS_CERTDIR=/certs
    volumes:
      - dind-certs-ca:/certs/ca
      - dind-certs-client:/certs/client
      - dind-data:/var/lib/docker
    networks:
      - admin-net
    command: ["--storage-driver=overlay2"]

  # Aider - AI pair programming in terminal
  aider:
    build:
      context: ./aider
      dockerfile: Dockerfile
    container_name: aider
    restart: unless-stopped
    volumes:
      - code-workspace:/workspace
      - ~/.gitconfig:/root/.gitconfig:ro
      - ~/.ssh:/root/.ssh:ro
      - dind-certs-client:/certs/client:ro
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - DOCKER_HOST=tcp://dind:2376
      - DOCKER_TLS_VERIFY=1
      - DOCKER_CERT_PATH=/certs/client
    command: ["--architect", "--no-auto-commits"]
    networks:
      - admin-net
    depends_on:
      - dind
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.aider.rule=Host(`aider.nexus.hugo.dk`)"
      - "traefik.http.services.aider.loadbalancer.server.port=8080"

  # OpenCodex - Visual Studio Code with AI
  opencodex:
    image: codercom/code-server:latest
    container_name: opencodex
    restart: unless-stopped
    environment:
      - PASSWORD=${CODE_SERVER_PASSWORD}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - code-workspace:/home/coder/workspace
      - opencodex-config:/home/coder/.config
    networks:
      - admin-net
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.opencodex.rule=Host(`code.nexus.hugo.dk`)"
      - "traefik.http.services.opencodex.loadbalancer.server.port=8080"

  # AI Chat Interface (supports multiple models)
  aichat:
    build:
      context: ./aichat
      dockerfile: Dockerfile
    container_name: aichat
    restart: unless-stopped
    environment:
      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Anthropic Claude
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # GitHub Models
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      # Google
      - GOOGLE_AI_API_KEY=${GOOGLE_AI_API_KEY}
      # Local models
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - aichat-data:/data
    networks:
      - admin-net
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.aichat.rule=Host(`ai.nexus.hugo.dk`)"
      - "traefik.http.services.aichat.loadbalancer.server.port=3000"

  # Ollama - Local LLM runner
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ollama-models:/root/.ollama
    networks:
      - admin-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Claude Engineer - Claude-specific development assistant
  claude-engineer:
    build:
      context: ./claude-engineer
      dockerfile: Dockerfile
    container_name: claude-engineer
    restart: unless-stopped
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - code-workspace:/workspace
    networks:
      - admin-net
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.claude.rule=Host(`claude.nexus.hugo.dk`)"
      - "traefik.http.services.claude.loadbalancer.server.port=8501"

  # Continue.dev - AI autocomplete for IDEs
  continue-server:
    build:
      context: ./continue
      dockerfile: Dockerfile
    container_name: continue
    restart: unless-stopped
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    networks:
      - admin-net
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.continue.rule=Host(`continue.nexus.hugo.dk`)"
      - "traefik.http.services.continue.loadbalancer.server.port=3000"

  # Sandbox environments for testing
  sandbox-python:
    image: python:3.11-slim
    container_name: ai-sandbox-python
    restart: unless-stopped
    command: ["sleep", "infinity"]
    volumes:
      - sandbox-data:/sandbox
    networks:
      - admin-net
    cap_drop:
      - ALL
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp

  sandbox-node:
    image: node:20-slim
    container_name: ai-sandbox-node
    restart: unless-stopped
    command: ["sleep", "infinity"]
    volumes:
      - sandbox-data:/sandbox
    networks:
      - admin-net
    cap_drop:
      - ALL
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp

volumes:
  code-workspace:
  opencodex-config:
  aichat-data:
  ollama-models:
  sandbox-data:

networks:
  admin-net:
    external: true
    name: tabby-admin_default